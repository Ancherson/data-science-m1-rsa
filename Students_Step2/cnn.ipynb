{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 17:11:47.171902: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 17:11:48.146950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = pd.read_csv(\"InputTrain.csv\")\n",
    "washing_machine = pd.read_csv(\"StepTwo_LabelTrain_WashingMachine.csv\")\n",
    "dishwasher = pd.read_csv(\"StepTwo_LabelTrain_Dishwasher.csv\")\n",
    "tumble_dryer = pd.read_csv(\"StepTwo_LabelTrain_TumbleDryer.csv\")\n",
    "microwave = pd.read_csv(\"StepTwo_LabelTrain_Microwave.csv\")\n",
    "kettle = pd.read_csv(\"StepTwo_LabelTrain_Kettle.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour transformer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(machine,name):\n",
    "    time_stamps = []\n",
    "    for elt in machine.columns :\n",
    "        if str.startswith(elt,'TimeStep') :\n",
    "            time_stamps.append(elt)\n",
    "    machine = pd.melt(machine,id_vars=['Index','House_id'],value_vars= time_stamps, var_name='time',value_name = name)\n",
    "\n",
    "    machine = pd.DataFrame(machine)\n",
    "    times = []\n",
    "    for elt in machine['time']:\n",
    "        times.append(int(elt[9:]))\n",
    "    machine['time'] = times\n",
    "    machine = machine.sort_values(['Index','time'])\n",
    "    return machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "washing_machine = transform(washing_machine,'Washing Machine')\n",
    "dishwasher = transform(dishwasher,'Dishwasher')\n",
    "tumble_dryer = transform(tumble_dryer,'Tumble Dryer')\n",
    "microwave = transform(microwave,'Microwave')\n",
    "kettle = transform(kettle,'Kettle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrouper les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machines = [washing_machine,dishwasher,tumble_dryer,microwave,kettle]\n",
    "\n",
    "consumption = transform(consumption,'watt')\n",
    "display(consumption)\n",
    "\n",
    "\n",
    "df_train = pd.concat([consumption,washing_machine['Washing Machine'],dishwasher['Dishwasher'],tumble_dryer['Tumble Dryer'],microwave['Microwave'],kettle['Kettle']],keys=['Index', 'House_id','time','watt','Washing Machine', 'Dishwasher', 'Tumble Dryer', 'Microwave', 'Kettle', 'watt'],axis=1,join=\"inner\")\n",
    "display(df_train)\n",
    "print(len(df_train[df_train[\"Index\"] == 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "seq_len = 2160\n",
    "n_features = 1\n",
    "n_targets = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du générateur de données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df, batch_size):\n",
    "    num_curves = len(df['Index'].unique())\n",
    "    num_batches_per_epoch = num_curves // batch_size\n",
    "\n",
    "    while True:\n",
    "        # Mélange aléatoire des courbes\n",
    "        shuffled_curves = np.random.permutation(df['Index'].unique())\n",
    "\n",
    "        # Pour chaque batch\n",
    "        for i in range(num_batches_per_epoch):\n",
    "            # Sélection aléatoire de batch_size courbes\n",
    "            batch_curves = shuffled_curves[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            # Initialisation des tenseurs d'entrée et de sortie du batch\n",
    "            X_batch = np.zeros((batch_size, seq_len, n_features))\n",
    "            y_batch = np.zeros((batch_size, seq_len, n_targets))\n",
    "\n",
    "            # Remplissage des tenseurs d'entrée et de sortie du batch\n",
    "            for j, curve in enumerate(batch_curves):\n",
    "                curve_data = df[df['Index'] == curve]\n",
    "                X_batch[j, :, 0] = curve_data['watt'].values\n",
    "                y_batch[j,:,:] = curve_data[['Washing Machine', 'Dishwasher', 'Tumble Dryer', 'Microwave', 'Kettle']].values\n",
    "\n",
    "            yield (X_batch, y_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(seq_len, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_targets, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generate_data(df_train, batch_size), steps_per_epoch=len(df_train['Index'].unique()) // batch_size, epochs=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les données de test dans une DataFrame Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"InputTest.csv\")\n",
    "df_test = transform(df_test,\"watt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génération des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(df):\n",
    "    for _, curve_data in df.groupby('Index'):\n",
    "        X = np.array(curve_data[['watt']].values).reshape(1, -1, 1)\n",
    "        yield X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction des états des appareils pour chaque courbe de consommation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for X_test in generate_test_data(df_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_pred.append(y_test_pred[0,:,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un DataFrame pour les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=np.array(y_pred).reshape(-1, 5), columns=['Washing Machine', 'Dishwasher', 'Tumble Dryer', 'Microwave', 'Kettle'])\n",
    "result_df = result_df.round(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportation des résultats au format CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('results.csv', index=True,index_label=\"Index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
